from playwright.sync_api import sync_playwright, Playwright
from datetime import datetime
from progress_state import load_state, save_state, save_to_csv, save_to_csv_init


start_time = datetime.now()
print(f"Tiempo de inicio: {start_time}")

BASE_URL = "URL_DE_EJEMPLO" # Reemplazar con la URL base real si es necesario
TARGET_URL = "URL_DE_EJEMPLO" # Reemplazar con la URL real

data = []

def run(playwright: Playwright) -> None:
    url = TARGET_URL
    chrome = playwright.chromium
    browser = chrome.launch(headless=False)
    context = browser.new_context()
    
    # Bloquear carga de imÃ¡genes para acelerar
    def route_intercept(route):
        if route.request.resource_type == "image":
            route.abort()
        else:
            route.continue_()
            
    context.route("**/*", route_intercept)
    
    page = context.new_page()

    # Cargar estado previo
    state = load_state()
    start_page = state["last_page"] + 1
    processed_urls = set(state["processed_urls"])
    processed_documents_urls = set(state["processed_documents_urls"])
    
    print(f"ğŸ“Œ Iniciando desde la pÃ¡gina {start_page}")
    print(f"ğŸ“Š URLs ya procesadas: {len(processed_urls)}")
    print(f"ğŸ“Š Documentos ya procesados: {len(processed_documents_urls)}")
    response = page.goto(url)

    if response and (response.status == 500 or response.status == 404):
        print(f"  âš ï¸  Error {response.status}  url: {url}")
        page.close()
        return

    # Navegar a la pÃ¡gina donde quedamos
    if start_page > 1:
        print(f"â© Avanzando a la pÃ¡gina {start_page}...")
        for _ in range(start_page - 1):
            next_btn = page.locator('') # Completar con el selector adecuado
            if next_btn.count() > 0:
                next_btn.click()
            else:
                print("âš ï¸ No se pudo avanzar, iniciando desde pÃ¡gina actual")
                break    
    
    
    current_page = start_page
    page_data = []  # Datos de la pÃ¡gina actual

    while True:
        # LÃ³gica para procesar la pÃ¡gina actual
        elements = page.locator('').all() # Completar con el selector adecuado
        print(f"\nğŸ“„ Procesando pÃ¡gina {current_page} ({len(elements)} elementos)")

        for idx, element in enumerate(elements, 1):
            element_page = context.new_page() # Abrir nueva pestaÃ±a            
            element_url = element.get_attribute("href") # or BASE_URL + element.get_attribute("href") # Completa el atributo href si es necesario
            
            # Saltar si ya procesamos esta URL
            if element_url in processed_urls:
                print(f"  â­ï¸  [{idx}/{len(elements)}] Ya procesada, saltando...")
                element_page.close()
                continue

            if element_url in processed_urls:
                print(f"     â­ï¸  Ya procesada: {element_url}")
                continue

            if element_url is not None:
                try:
                    response = element_page.goto(element_url)
                    document_url = element_page.locator('').text_content()  # Completar con el selector adecuado
                    if document_url in processed_documents_urls:
                        print(f"     â­ï¸  Documento procesado: {document_url}")
                        continue

                    page_data.append([title, element_url])  # Guardar datos de la publicaciÃ³n
                    processed_urls.add(element_url)
                    print(f"  âœ… [{idx}/{len(elements)}] {title[:50]}...")

                except Exception as e:
                    print(f"  âŒ [{idx}/{len(elements)}] {title[:50]}... Â¡Scraping interrumpido! \n{element_page.url}")
                                        
                    end_time = datetime.now()
                    duration = end_time - start_time
                    
                    print(f"  âŒ Tiempo total: {duration}")
                    print(f"  âŒ Error: {e}")                 
                    
                    return
                finally:
                    element_page.close()
            else:
                element_page.close()    

        # Guardar progreso de esta pÃ¡gina
        if page_data:
            if current_page == 1:
                # Inicializar CSV
                save_to_csv_init([['TÃ­tulo', 'Fecha','Document_URL']]) # titulos de las columnas
            save_to_csv(page_data)
            data.extend(page_data)
            print(f"ğŸ’¾ Guardados {len(page_data)} registros de la pÃ¡gina {current_page}")
            page_data = []
        
        # Guardar estado
        save_state(current_page, list(processed_urls), list(processed_documents_urls))

        # LÃ³gica de paginacion y break
        page_number = page.locator('') # Completar con el selector adecuado
        print(f"ğŸ“ PÃ¡gina {page_number[0]} de {page_number[2]}")

        if int(page_number[0]) >= int(page_number[2]):
            end_time = datetime.now()
            duration = end_time - start_time
            print(f"Tiempo total: {duration}")
            print("\nâœ… Â¡Scraping completado!")
            break
        else:
            # Navegar a la siguiente pÃ¡gina
            next_button = page.locator('') # Completar con el selector adecuado
            if next_button.is_enabled():
                next_button.click()
                current_page += 1
            else:
                print("  âš ï¸  No se pudo encontrar el botÃ³n de siguiente pÃ¡gina.")
                break

    print(f"\nğŸ“Š Total de registros extraÃ­dos: {len(data)}")
    browser.close()

with sync_playwright() as playwright:
    run(playwright)